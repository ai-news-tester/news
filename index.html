<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Strict AI News Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css">
  <style>
    .divider {
      border-top: 2px solid red;
      margin: 20px 0;
      padding-top: 10px;
      text-align: center;
      color: red;
      font-weight: bold;
    }
  </style>
</head>
<body>
<div class="container mt-5">
  <h1 class="mb-4">Latest AI News</h1>

  <div class="card mb-3">
    <img src="https://i.insider.com/67c95d9ab1834fe311665088?width=1200&format=jpeg" class="card-img-top" alt="The US has been watching DeepSeek since late 2023 and still has a way to beat it, Biden's former AI advisor says">
    <div class="card-body">
      <h5 class="card-title">The US has been watching DeepSeek since late 2023 and still has a way to beat it, Biden's former AI advisor says</h5>
      <p class="card-text">"We should tighten the screws and continue to constrain them," Ben Buchanan said of DeepSeek.</p>
      <button class="btn btn-primary" type="button" data-bs-toggle="collapse" data-bs-target="#collapse0" aria-expanded="false" aria-controls="collapse0">
        Read More
      </button>
      <div class="collapse mt-2" id="collapse0">
        <div class="card card-body">
          <p>DeepSeek has long been on the US government's radar.

A former AI advisor for the Biden administration said the US has been watching DeepSeek since late 2023.

He said the US should "tighten the screws and continue to constrain them."

DeepSeek's capabilities shocked the markets, but a former special advisor for artificial intelligence in the Biden administration says the Chinese AI firm was on the US government's radar — and had been for over a year.

"We had been watching DeepSeek in the White House since November 2023 or thereabouts, when they put out their first coding system," Ben Buchanan said during the latest episode of "The Ezra Klein Show," which aired on Tuesday.

"There's no doubt that DeepSeek engineers are extremely talented, and they got better and better at their systems throughout 2024," Buchanan added.

Buchanan, now an assistant professor at Johns Hopkins University, served in the Biden administration from June 2021 to this January. He held roles in the White House Office of Science and Technology Policy and the National Security Council before becoming President Joe Biden's special advisor for AI in June 2023.

Buchanan told Klein that while DeepSeek's accomplishments have been impressive, he didn't think the "media hype around it was warranted."

DeepSeek triggered a sell-off in AI-related stocks in January after the startup's high-performing and cheap models sparked concerns that demand for AI hardware could fall.

However, Buchanan said that DeepSeek is "doing exactly the same kind of algorithmic efficiency work" as other AI companies, like OpenAI and Anthropic.

"They still are constrained by computing power," Buchanan said of DeepSeek. "We should tighten the screws and continue to constrain them."

"And this should be a reminder that chip controls are important, China is a worthy competitor here, and we shouldn't take anything for granted," Buchanan added. "But I don't think this is the time to say the sky is falling or the fundamental scaling laws have broken."

In January, President Donald Trump told GOP lawmakers at the party's annual policy retreat that he saw DeepSeek's cheaper models as "a positive, as an asset."

"The release of DeepSeek, AI from a Chinese company, should be a wake-up call for our industries that we need to be laser-focused on competing to win," Trump said.

Representatives for DeepSeek and the White House did not respond to requests for comment from Business Insider.</p>
          <a href="https://www.businessinsider.com/biden-ai-advisor-us-watching-deepseek-since-late-2023-2025-3" target="_blank">Visit Original Article</a>
        </div>
      </div>
      <p class="card-text pub-date" data-pub-date="2025-03-06T11:19:25Z">
        <small class="text-muted">Published at: 2025-03-06 11:19</small>
      </p>
    </div>
  </div>

  <div class="card mb-3">
    <img src="https://res.infoq.com/news/2025/03/AI-analysis-automated-test/en/headerimage/ai-analysis-automated-test-header-1739960687267.jpg" class="card-img-top" alt="Using Artificial Intelligence for Analysis of Automated Testing Results">
    <div class="card-body">
      <h5 class="card-title">Using Artificial Intelligence for Analysis of Automated Testing Results</h5>
      <p class="card-text">Analysis of automated testing results is a very important and challenging part of testing activities. At any given moment we should be able to tell the state of our product according to the results of automated tests, Maroš Kutschy said at QA Challenge Accept…</p>
      <button class="btn btn-primary" type="button" data-bs-toggle="collapse" data-bs-target="#collapse1" aria-expanded="false" aria-controls="collapse1">
        Read More
      </button>
      <div class="collapse mt-2" id="collapse1">
        <div class="card card-body">
          <p>Analysis of automated testing results is a very important and challenging part of testing activities. At any given moment we should be able to tell the state of our product according to the results of automated tests, Maroš Kutschy said at QA Challenge Accepted. He presented how artificial intelligence helps them save time spent on analysis, reduce human errors, and focus on new failures.

Kutschy mentioned that they faced challenges with the analysis of automated test results, and were looking for a way to make the analysis more effective and less prone to human errors:

If you have around 4000 test scenarios running each night and if around 5% of them are failing, you need to analyse around 200 failures each day.

They introduced the tool ReportPortal which uses artificial intelligence to analyse automated test results. This tool can be installed for free as an on-prem solution, as Kutschy explained:

I am the administrator, I did the proof of concept and the integration and I solved any issues. Colleague testers who work in feature teams are using it on a daily basis.

Testers log in to ReportPortal, find the results of the job for which they are responsible, and see how many failures are in "To Investigate" status, Kutschy said. Failures that existed on the previous day (which have been analyzed previously) are already categorized by ReportPortal. For failures in the "To Investigate" status, they need to do a standard round of analysis, which means debugging the tests and finding the root cause of the failure:

ReportPortal shows the output of the analysis; you can see how many scenarios failed because of product bugs, automation bugs, environment issues and how many failures are still in "To Investigate" status.

When you start using the tool, it knows nothing about the failures, Kutschy said. Testers need to decide if the failure is a product bug, automation bug, or environmental issue. The next time the same failure arrives in the system, then the correct status will be assigned to the failure according to previous decisions, using artificial intelligence.

Kutschy mentioned that the dashboards representing the results of the analysis provide a high-level view of the testing and the state of the application. The visibility of the state of analysis is in real-time, you see who is working on which failure. This helps to decide if it is possible to release the application or not.

With the tool they save time spent on analysis, as they look only at new failures, not at all of the failures, as Kutschy explained:

The difference is that if you have 100 failures today and only 2 of them are new, you only need to look at 2 failures. If you are not using the tool, you need to look at 100 failures, Kutschy mentioned.

There are also fewer human errors, as the tool does the triage of old failures for you based on previous decisions made by you. This helps to focus attention on new failures, Kutschy said.

Artificial intelligence will make the wrong decisions if humans train it with incorrect data, Kutschy said. If you are a bad teacher, your student (ReportPortal) will perform badly:

There were situations where one of the colleagues linked failure to an incorrect Jira ticket or assigned incorrect status to the failure.

You can "unlearn" by changing the decision manually, Kutschy mentioned.

If you use artificial intelligence correctly, it can save you a lot of time and will reduce human mistakes, Kutschy said. Once you verify that it is working correctly, you can rely on it instead of you and your colleagues having to triage the failures.

InfoQ Interviewed Maroš Kutschy about using artificial intelligence for the analysis of automated testing.

InfoQ: What challenges did you face along the way and how did you deal with them?

Maroš Kutschy: We started doing a proof of concept which confirmed that we could integrate the tool into our test automation framework. The challenge then was to get colleagues to follow the new process of analysing test results using ReportPortal. Initially, they needed to categorize all existing failures, which meant assigning them the correct status (automation issue, product bug, environmental issue) and Jira ticket. We ran a trial period for usage in selected teams and then all teams started using it. The feedback from the trial period was positive and the testers felt good about it, as it was helping them with the investigation.

InfoQ: What have you learned?

Kutschy: You have to verify that you can trust artificial intelligence before you start relying on it. We had to be sure that ReportPortal was making the correct decisions. The decision depended on how we handled stack traces in our test automation framework, and the settings of ReportPortal. In the case where it did not work as expected, we tried to play with the settings of ReportPortal. Most discussions are about using artificial intelligence to create test automation code, but we learned that the analysis of automated testing results is also a very suitable area. We can use artificial intelligence (including generative artificial intelligence) for many use cases in testing.</p>
          <a href="https://www.infoq.com/news/2025/03/AI-analysis-automated-test/" target="_blank">Visit Original Article</a>
        </div>
      </div>
      <p class="card-text pub-date" data-pub-date="2025-03-06T11:15:00Z">
        <small class="text-muted">Published at: 2025-03-06 11:15</small>
      </p>
    </div>
  </div>

  <div class="card mb-3">
    <img src="https://www.medianama.com/wp-content/uploads/2025/03/youtube-6513651_1280.jpg" class="card-img-top" alt="YouTube Warns Users Against Phishing Attempts Through AI-Generated Videos of CEO Neal Mohan">
    <div class="card-body">
      <h5 class="card-title">YouTube Warns Users Against Phishing Attempts Through AI-Generated Videos of CEO Neal Mohan</h5>
      <p class="card-text">The AI-generated video in question shows YouTube CEO announcing a monetization policy change and is an attempt to lure users to phishing sites. 
The post YouTube Warns Users Against Phishing Attempts Through AI-Generated Videos of CEO Neal Mohan appeared firs…</p>
      <button class="btn btn-primary" type="button" data-bs-toggle="collapse" data-bs-target="#collapse2" aria-expanded="false" aria-controls="collapse2">
        Read More
      </button>
      <div class="collapse mt-2" id="collapse2">
        <div class="card card-body">
          <p>Briefly Smartly

Video sharing platform YouTube has alerted users about an artificial intelligence (AI)-generated video of the company’s CEO, Neal Mohan, in which he is purportedly seen announcing changes in monetisation policy.

YouTube stated that this was likely a phishing attempt, and that following instructions shared in the video could lead to phishing sites, which could install malware into users’ devices or steal their credentials, as per a blog post.

“YouTube and its employees will never attempt to contact you or share information through a private video. If a video is shared privately with you claiming to be from YouTube, the video is a phishing scam”, the company said.

Further explaining, the platform said that many phishers actively target creators by using in-platform features to link to malicious content. The company suggested users to avoid opening files or links they do not trust.

The Gen AI trouble

AI-generated deepfakes are plaguing personal reputation, leading to financial misinformation, harming electoral discourse, and even spreading sexually explicit imagery across social media platforms. It is something that has been reported previously, with the Indian Government even mulling a separate legislation to tackle the dissemination of such questionable use of AI.

Why It Matters?

Although there has since been no movement from the Indian government with regard to the same, what several public figures like actor Jackie Shroff have done in recent years is access the benefits of securing their personality rights, thereby disallowing any unpermitted use of their name, voice, image, likeness of other unique aspects of their identities. MediaNama has discussed earlier if the eventual rise in AI use as well as personality rights protection, during the years to come, could result in legal battles in India.

Advertisements

While definitive answers are scarce in terms of which way disruptions in the field of AI are headed, regulating AI development could be an effective way to regulate AI responses when it comes to frontier AI development. Herein, however, instances such as the United States and European Union refusing to sign the recent Paris AI Action Summit joint statement on “Safe” AI brings in questions of unilateral efforts as opposed to a globally agreed-upon standpoint on the issue.

Also Read:</p>
          <a href="https://www.medianama.com/2025/03/223-youtube-warns-users-against-phishing-attempts-through-ai-generated-videos-of-ceo-neal-mohan/" target="_blank">Visit Original Article</a>
        </div>
      </div>
      <p class="card-text pub-date" data-pub-date="2025-03-06T11:11:38Z">
        <small class="text-muted">Published at: 2025-03-06 11:11</small>
      </p>
    </div>
  </div>

</div>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script>
document.addEventListener('DOMContentLoaded', function() {
  const lastSeen = localStorage.getItem('lastSeen');
  const cards = document.querySelectorAll('.card.mb-3');
  let dividerInserted = false;
  if (lastSeen) {
    cards.forEach(card => {
      const pubDateElem = card.querySelector('.pub-date');
      if (pubDateElem) {
        const pubDate = new Date(pubDateElem.getAttribute('data-pub-date'));
        if (pubDate < new Date(lastSeen) && !dividerInserted) {
          const divider = document.createElement('div');
          divider.className = 'divider';
          divider.innerText = 'Previously Seen Articles';
          card.parentNode.insertBefore(divider, card);
          dividerInserted = true;
        }
      }
    });
  }
  if (cards.length > 0) {
    const firstPubDate = cards[0].querySelector('.pub-date').getAttribute('data-pub-date');
    localStorage.setItem('lastSeen', firstPubDate);
  }
});
</script>
</body>
</html>
