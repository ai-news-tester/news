<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Strict AI News Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css">
  <style>
    .divider {
      border-top: 2px solid red;
      margin: 20px 0;
      padding-top: 10px;
      text-align: center;
      color: red;
      font-weight: bold;
    }
  </style>
</head>
<body>
<div class="container mt-5">
  <h1 class="mb-4">Latest AI News</h1>

  <div class="card mb-3">
    <img src="https://scx2.b-cdn.net/gfx/news/hires/2025/revealing-hidden-atomi.jpg" class="card-img-top" alt="Machine learning reveals hidden complexities in palladium oxidation, sheds light on catalyst behavior">
    <div class="card-body">
      <h5 class="card-title">Machine learning reveals hidden complexities in palladium oxidation, sheds light on catalyst behavior</h5>
      <p class="card-text">Researchers at the Fritz Haber Institute have developed the Automatic Process Explorer (APE), an approach that enhances our understanding of atomic and molecular processes. By dynamically refining simulations, APE has uncovered unexpected complexities in the …</p>
      <button class="btn btn-primary" type="button" data-bs-toggle="collapse" data-bs-target="#collapse0" aria-expanded="false" aria-controls="collapse0">
        Read More
      </button>
      <div class="collapse mt-2" id="collapse0">
        <div class="card card-body">
          <p>This article has been reviewed according to Science X's editorial process and policies . Editors have highlighted the following attributes while ensuring the content's credibility:

Schematic workflow of the MLIP-APE method. Credit: ACS Catal. 2025, 15, 1, 514-522

Researchers at the Fritz Haber Institute have developed the Automatic Process Explorer (APE), an approach that enhances our understanding of atomic and molecular processes. By dynamically refining simulations, APE has uncovered unexpected complexities in the oxidation of palladium (Pd) surfaces, offering new insights into catalyst behavior. The study is published in the journal Physical Review Letters.

Kinetic Monte Carlo (kMC) simulations are essential for studying the long-term evolution of atomic and molecular processes. They are widely used in fields like surface catalysis, where reactions on material surfaces are crucial for developing efficient catalysts that accelerate reactions in energy production and pollution control. Traditional kMC simulations rely on predefined inputs, which can limit their ability to capture complex atomic movements. This is where the Automatic Process Explorer (APE) comes in.

Developed by the Theory Department at the Fritz Haber Institute, APE overcomes biases in traditional kMC simulations by dynamically updating the list of processes based on the system's current state. This approach encourages exploration of new structures, promoting diversity and efficiency in structural exploration. APE separates process exploration from kMC simulations, using fuzzy machine-learning classification to identify distinct atomic environments. This allows for a broader exploration of potential atomic movements.

By integrating APE with machine-learned interatomic potentials (MLIPs), researchers applied it to the early-stage oxidation of palladium surfaces, a key system in pollution control. When applied to the early-stage oxidation of a palladium surface, a key material used in catalytic converters for cars to reduce emissions, APE uncovered nearly 3,000 processes, far exceeding the capabilities of traditional kMC simulations. These findings reveal complex atomic motions and restructuring processes that occur on timescales similar to molecular processes in catalysis.

The APE methodology provides a detailed understanding of Pd surface restructuring during oxidation, revealing complexities previously unseen. This research enhances our knowledge of nanostructure evolution and its role in surface catalysis. By improving the efficiency of catalysts, these insights have the potential to significantly impact energy production and environmental protection, contributing to cleaner technologies and more sustainable industrial processes.

More information: King Chun Lai et al, Automatic Process Exploration through Machine Learning Assisted Transition State Searches, Physical Review Letters (2025). DOI: 10.1103/PhysRevLett.134.096201 Journal information: Physical Review Letters</p>
          <a href="https://phys.org/news/2025-03-machine-reveals-hidden-complexities-palladium.html" target="_blank">Visit Original Article</a>
        </div>
      </div>
      <p class="card-text pub-date" data-pub-date="2025-03-06T20:49:54Z">
        <small class="text-muted">Published at: 2025-03-06 20:49</small>
      </p>
    </div>
  </div>

  <div class="card mb-3">
    <img src="https://i.nextmedia.com.au/News/taco bell.png" class="card-img-top" alt="Yum's Taco Bell shows off AI tool for fast food managers">
    <div class="card-body">
      <h5 class="card-title">Yum's Taco Bell shows off AI tool for fast food managers</h5>
      <p class="card-text">As a skit at investor presentation, causing confusion.</p>
      <button class="btn btn-primary" type="button" data-bs-toggle="collapse" data-bs-target="#collapse1" aria-expanded="false" aria-controls="collapse1">
        Read More
      </button>
      <div class="collapse mt-2" id="collapse1">
        <div class="card card-body">
          <p>Executives at Yum! Brands and Taco Bell this week showcased their "Byte by Yum" artificial intelligence-powered tools for restaurant managers, disclosing at an investor event that it has invested US$1 billion ($1.58 billion) into digital and technology.

Use of AI is "already beginning around labor and inventory," said Dane Mathews, Taco Bell's chief digital and technology officer, at the event.

To demonstrate its current and planned use of AI technology, chief operating officer Jason Kidd showed Wall Street analysts a video skit with a restaurant manager talking to a human character playing the role of an AI assistant, which Yum calls Byte AI Restaurant Coach.

"I noticed Brad hasn't clocked in yet for his shift, and you're heading into your last shift crew for the night," an actor playing the AI assistant says, addressing the Taco Bell manager.

"Maybe he's out sick. Don't worry if he is. I can work the drive-through," the AI character tells the manager.

About 500 Taco Bell US locations have AI voice technology to take drive-through orders, according to a slide that the executives showed following the skit.

That is up from the roughly 100 locations that Yum cited in July 2024.

One analyst, from Morgan Stanley, called Yum's video skit "very cool and slightly unsettling."

Yum's chief technology officer, Joe Park, said Taco Bell does not plan to use AI to reduce its labor costs, but rather to free up its employees to do other tasks.

'Long road ahead'

Fast food corporations are increasingly turning to tech to overhaul a business model that until recently had remained the same since the 1940s.

The last decade or so has seen a proliferation of kiosks, digital menus, apps, AI-assisted drive-throughs, and loyalty programs.

Chipotle's US$100 million venture fund has helped spur its efforts to partially automate its kitchens.

McDonald's announced in 2023 a partnership with Google Cloud to in part deploy AI tech to its locations, though that backfired for a day in 2024 when system outages made ordering impossible in some of its largest markets.

At Yum, Mathews said there is "still a long road ahead of us."

Nearly 25,000 of Yum's 61,000 restaurants globally use one of its in-house "Byte by Yum" tech products, Yum said in a February 6 statement.

In the Taco Bell skit, the character playing the manager's AI-assistant computes that a worker has been scheduled for fewer than her usual weekly hours, and prods the manager to "see if she wants to stick around the next hour" to reduce customer wait times.

Also noting that a "competitor down the street" reduced its hours of operation, the AI assistant suggested that the manager expand his own restaurant's hours, citing a surge in late night sales.

The AI assistant offered to help the manager calculate inventory. "Awesome, that's a real time-saver," the manager says in the skit.

A Yum spokeswoman did not immediately reply to a request for comment on whether AI is currently performing these tasks at any Taco Bell locations, or if the skit only showed its future ambitions.

Yum disclosed a projected eight percent increase in Taco Bell same store sales in the current quarter.

Yum's in-house software suite "really excited us," Bernstein analysts who attended the event said in a note for investors.

Yum could potentially one day sell the software "outside the Yum ecosystem," they said.</p>
          <a href="https://www.itnews.com.au/news/yums-taco-bell-shows-off-ai-tool-for-fast-food-managers-615499?utm_source=feed&utm_medium=rss&utm_campaign=iTnews+News+feed" target="_blank">Visit Original Article</a>
        </div>
      </div>
      <p class="card-text pub-date" data-pub-date="2025-03-06T20:36:00Z">
        <small class="text-muted">Published at: 2025-03-06 20:36</small>
      </p>
    </div>
  </div>

  <div class="card mb-3">
    <img src="https://i.nextmedia.com.au/News/taco bell.png" class="card-img-top" alt="Yum's Taco Bell shows off AI tool for fast food managers">
    <div class="card-body">
      <h5 class="card-title">Yum's Taco Bell shows off AI tool for fast food managers</h5>
      <p class="card-text">As a skit at investor presentation, causing confusion.</p>
      <button class="btn btn-primary" type="button" data-bs-toggle="collapse" data-bs-target="#collapse2" aria-expanded="false" aria-controls="collapse2">
        Read More
      </button>
      <div class="collapse mt-2" id="collapse2">
        <div class="card card-body">
          <p>Executives at Yum! Brands and Taco Bell this week showcased their "Byte by Yum" artificial intelligence-powered tools for restaurant managers, disclosing at an investor event that it has invested US$1 billion ($1.58 billion) into digital and technology.

Use of AI is "already beginning around labor and inventory," said Dane Mathews, Taco Bell's chief digital and technology officer, at the event.

To demonstrate its current and planned use of AI technology, chief operating officer Jason Kidd showed Wall Street analysts a video skit with a restaurant manager talking to a human character playing the role of an AI assistant, which Yum calls Byte AI Restaurant Coach.

"I noticed Brad hasn't clocked in yet for his shift, and you're heading into your last shift crew for the night," an actor playing the AI assistant says, addressing the Taco Bell manager.

"Maybe he's out sick. Don't worry if he is. I can work the drive-through," the AI character tells the manager.

About 500 Taco Bell US locations have AI voice technology to take drive-through orders, according to a slide that the executives showed following the skit.

That is up from the roughly 100 locations that Yum cited in July 2024.

One analyst, from Morgan Stanley, called Yum's video skit "very cool and slightly unsettling."

Yum's chief technology officer, Joe Park, said Taco Bell does not plan to use AI to reduce its labor costs, but rather to free up its employees to do other tasks.

'Long road ahead'

Fast food corporations are increasingly turning to tech to overhaul a business model that until recently had remained the same since the 1940s.

The last decade or so has seen a proliferation of kiosks, digital menus, apps, AI-assisted drive-throughs, and loyalty programs.

Chipotle's US$100 million venture fund has helped spur its efforts to partially automate its kitchens.

McDonald's announced in 2023 a partnership with Google Cloud to in part deploy AI tech to its locations, though that backfired for a day in 2024 when system outages made ordering impossible in some of its largest markets.

At Yum, Mathews said there is "still a long road ahead of us."

Nearly 25,000 of Yum's 61,000 restaurants globally use one of its in-house "Byte by Yum" tech products, Yum said in a February 6 statement.

In the Taco Bell skit, the character playing the manager's AI-assistant computes that a worker has been scheduled for fewer than her usual weekly hours, and prods the manager to "see if she wants to stick around the next hour" to reduce customer wait times.

Also noting that a "competitor down the street" reduced its hours of operation, the AI assistant suggested that the manager expand his own restaurant's hours, citing a surge in late night sales.

The AI assistant offered to help the manager calculate inventory. "Awesome, that's a real time-saver," the manager says in the skit.

A Yum spokeswoman did not immediately reply to a request for comment on whether AI is currently performing these tasks at any Taco Bell locations, or if the skit only showed its future ambitions.

Yum disclosed a projected eight percent increase in Taco Bell same store sales in the current quarter.

Yum's in-house software suite "really excited us," Bernstein analysts who attended the event said in a note for investors.

Yum could potentially one day sell the software "outside the Yum ecosystem," they said.</p>
          <a href="https://www.itnews.com.au/news/yums-taco-bell-shows-off-ai-tool-for-fast-food-managers-615499?utm_source=feed&utm_medium=rss&utm_campaign=iTnews+Software+feed" target="_blank">Visit Original Article</a>
        </div>
      </div>
      <p class="card-text pub-date" data-pub-date="2025-03-06T20:36:00Z">
        <small class="text-muted">Published at: 2025-03-06 20:36</small>
      </p>
    </div>
  </div>

  <div class="card mb-3">
    <img src="https://brobible.com/wp-content/uploads/2025/03/AI-Voice-Computational-Linguistics-Concept.jpg" class="card-img-top" alt="New AI Voice Is So Realistic People Can’t Tell It Apart From A Real Human">
    <div class="card-body">
      <h5 class="card-title">New AI Voice Is So Realistic People Can’t Tell It Apart From A Real Human</h5>
      <p class="card-text">Artificial intelligence startup Sesame recently released an AI voice demo that is so realistic people can’t tell it apart from a real human. In fact, it’s so realistic that it is reportedly making people both amazed as well as very uncomfortable. According to…</p>
      <button class="btn btn-primary" type="button" data-bs-toggle="collapse" data-bs-target="#collapse3" aria-expanded="false" aria-controls="collapse3">
        Read More
      </button>
      <div class="collapse mt-2" id="collapse3">
        <div class="card card-body">
          <p>iStockphoto

Artificial intelligence startup Sesame recently released an AI voice demo that is so realistic people can’t tell it apart from a real human. In fact, it’s so realistic that it is reportedly making people both amazed as well as very uncomfortable.

According to Senior AI Reporter Benj Edwards at Ars Technica, who had a conversation with Sesame’s new Conversational Speech Model (CSM) for about 28 minutes, “The synthesized voice was expressive and dynamic, imitating breath sounds, chuckles, interruptions, and even sometimes stumbling over words and correcting itself. These imperfections are intentional.”

“At Sesame, our goal is to achieve ‘voice presence’ — the magical quality that makes spoken interactions feel real, understood, and valued,” Sesame explained on their website. “We are creating conversational partners that do not just process requests; they engage in genuine dialogue that builds confidence and trust over time. In doing so, we hope to realize the untapped potential of voice as the ultimate interface for instruction and understanding.”

Someone else who tested out Sesame’s AI voice demo and posted their reactions on the Hacker News forum wrote, “It was genuinely startling how human it felt. Apparently they are planning on open-sourcing some of their work as well as selling glasses (presumably with the voice assistant). I’m very excited to have a voice assistant like this and am almost a bit worried I will start feeling emotionally attached to a voice assistant with this level of human-like sound.”

Want to try it out for yourself? Just click here.

Another person who spoke with Sesame’s AI voice demo, Mark Hachman, a senior editor at PCWorld, revealed, “Fifteen minutes after ‘hanging up’ with Sesame’s new ‘lifelike’ AI, and I’m still freaked out.”

One of the big reasons people should feel “freaked out” by this new human-sounding AI voice is obvious: scams. As Edwards writes, “As synthetic voices become increasingly indistinguishable from human speech, you may never know who you’re talking to on the other end of the line.”</p>
          <a href="https://brobible.com/culture/article/new-ai-voice-realistic-apart-human/" target="_blank">Visit Original Article</a>
        </div>
      </div>
      <p class="card-text pub-date" data-pub-date="2025-03-06T20:35:16Z">
        <small class="text-muted">Published at: 2025-03-06 20:35</small>
      </p>
    </div>
  </div>

  <div class="card mb-3">
    
    <div class="card-body">
      <h5 class="card-title">I Don't Care if Conversational Siri Lands on My iPhone in 2027 or Ever - CNET</h5>
      <p class="card-text">I Don't Care if Conversational Siri Lands on My iPhone in 2027 or EverCNET Apple’s Artificial Intelligence Efforts Reach a Make-or-Break PointBloomberg Siri’s Major Apple Intelligence Upgrade Is Now Expected To Arrive With iOS 18.5 Instead Of iOS 18.4, As App…</p>
      <button class="btn btn-primary" type="button" data-bs-toggle="collapse" data-bs-target="#collapse4" aria-expanded="false" aria-controls="collapse4">
        Read More
      </button>
      <div class="collapse mt-2" id="collapse4">
        <div class="card card-body">
          <p>Mathematics deals exclusively with the relations of concepts to each other without consideration of their relation to experience. -- Albert Einstein</p>
          <a href="https://slashdot.org/firehose.pl?op=view&amp;id=176636455" target="_blank">Visit Original Article</a>
        </div>
      </div>
      <p class="card-text pub-date" data-pub-date="2025-03-06T20:33:15Z">
        <small class="text-muted">Published at: 2025-03-06 20:33</small>
      </p>
    </div>
  </div>

</div>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script>
document.addEventListener('DOMContentLoaded', function() {
  const lastSeen = localStorage.getItem('lastSeen');
  const cards = document.querySelectorAll('.card.mb-3');
  let dividerInserted = false;
  if (lastSeen) {
    cards.forEach(card => {
      const pubDateElem = card.querySelector('.pub-date');
      if (pubDateElem) {
        const pubDate = new Date(pubDateElem.getAttribute('data-pub-date'));
        if (pubDate < new Date(lastSeen) && !dividerInserted) {
          const divider = document.createElement('div');
          divider.className = 'divider';
          divider.innerText = 'Previously Seen Articles';
          card.parentNode.insertBefore(divider, card);
          dividerInserted = true;
        }
      }
    });
  }
  if (cards.length > 0) {
    const firstPubDate = cards[0].querySelector('.pub-date').getAttribute('data-pub-date');
    localStorage.setItem('lastSeen', firstPubDate);
  }
});
</script>
</body>
</html>
