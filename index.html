<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Strict AI News Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css">
  <style>
    .divider {
      border-top: 2px solid red;
      margin: 20px 0;
      padding-top: 10px;
      text-align: center;
      color: red;
      font-weight: bold;
    }
  </style>
</head>
<body>
<div class="container mt-5">
  <h1 class="mb-4">Latest AI News</h1>

  <div class="card mb-3">
    <img src="https://www.medianama.com/wp-content/uploads/2018/04/united-states-capitol-1675540_1920-1.jpg-1.jpg" class="card-img-top" alt="Anthropic Quietly Removes Biden-Era AI Safety Pledge From Its Website">
    <div class="card-body">
      <h5 class="card-title">Anthropic Quietly Removes Biden-Era AI Safety Pledge From Its Website</h5>
      <p class="card-text">American AI firm Anthropic has quietly removed its Biden-era commitments to AI safety and security in a nod to the new Trump administration.
The post Anthropic Quietly Removes Biden-Era AI Safety Pledge From Its Website appeared first on MEDIANAMA.</p>
      <button class="btn btn-primary" type="button" data-bs-toggle="collapse" data-bs-target="#collapse0" aria-expanded="false" aria-controls="collapse0">
        Read More
      </button>
      <div class="collapse mt-2" id="collapse0">
        <div class="card card-body">
          <p>Briefly Smartly

Major US artificial intelligence (AI) firm Anthropic has quietly removed the voluntary commitments it had made towards AI safety last year, AI watchdog group The Midas Project informed yesterday.

Anthropic removed “White House’s Voluntary Commitments for Safe, Secure, and Trustworthy AI,” which was introduced during US President Joe Biden’s term. The commitments were removed “seemingly without a trace, from their webpage “Transparency Hub“, The Midas Project remarked. It also noted that other changes apart from this one remained minor.

Why It Matters

In July 2023, several AI companies including Amazon, Anthropic, Google, Inflection, Meta, Microsoft, and OpenAI, had agreed to comply with the aforementioned AI commitments. This was received with much celebration and hopes of building an AI ecosystem that would champion transparency and safety while also bringing the much-touted AI solutions to people’s daily lives.

As part of this commitment, Anthropic stated that it would:

Share insights on managing AI risks across both industry and government sectors.

Conduct in-depth research into AI bias and discrimination to ensure fairer algorithms.

Do these forward-looking company policies then need to change with changing administrations? The Midas Project pointed out in its tweet: “nothing in the commitments suggested that the promise was (1) time-bound or (2) contingent on the party affiliation of the sitting president.”

This step seems to be a part of a trend with safety and trust in AI taking a backseat. OpenAI in the last couple of months has rolled out updates and initiatives that have focused on the newly elected government’s stance on key policy matters. Just last month, it updated its policy to state that its AI models should “empower people to explore, debate, and create without arbitrary restrictions—no matter how challenging or controversial a topic may be.” Additionally, in January this year, it also launched a new ChatGPT version tailor-made for the United States Government called ChatGPT Gov. The company informed that the launch of the tool reflects its “commitment to helping U.S. government agencies leverage OpenAI’s technology” and also referred to one of US President Donald Trump’s executive orders (EOs).

Another important thing noted by The Midas Project about this move was that Anthropic removed the commitments from its website – an online resource aimed at “raising the bar on transparency” – without any trace.

Changing landscape of AI regulations

AI regulations in the US have undergone some major changes since US President Donald Trump took over the country’s administration for the second time. In one of the first moves he made after assuming the office, he signed several EOs, many of which repealed actions taken under Biden. One of them was a 2023 directive that outlined measures for ensuring AI safety and security, citizen privacy, equity, protection of consumers and workers’ rights, and promoting innovation.

The EO that repealed the earlier directive was among many others that are being seen as regressive steps in American political scenario. While some believe some of these EOs will face legal challenges since they are subject to judicial review and may be blocked if they violate the Constitution of the United States, the same has not been said about the one on AI safety commitments.

Advertisements

This could be because AI in general remains a topic that is largely still under discussion at the regulatory level or can even be a point of divergence. Just last month, both the US and UK refused to sign the Paris AI Action Summit Joint Statement on “safe” AI. While UK said it had concerns about how national security plays out under the provisions of the statement, US said it was against too much regulation and instead prioritised innovation over safety in the AI domain.

Back home, the Indian government has also been giving mixed signals about its approach with its fluctuating stance on heavy and light touch regulation.

Read More:</p>
          <a href="https://www.medianama.com/2025/03/223-anthropic-removes-biden-era-ai-safety-pledge-nod-to-trump-admin/" target="_blank">Visit Original Article</a>
        </div>
      </div>
      <p class="card-text pub-date" data-pub-date="2025-03-06T11:56:35Z">
        <small class="text-muted">Published at: 2025-03-06 11:56</small>
      </p>
    </div>
  </div>

  <div class="card mb-3">
    <img src="https://biztoc.com/cdn/906/og.png" class="card-img-top" alt="1 Mind-Boggling Number From Nvidia's Q4 Earnings That May Have You Thinking Twice About Whether the Stock Peaked">
    <div class="card-body">
      <h5 class="card-title">1 Mind-Boggling Number From Nvidia's Q4 Earnings That May Have You Thinking Twice About Whether the Stock Peaked</h5>
      <p class="card-text">Chipmaker Nvidia (NASDAQ: NVDA) has been a growth beast over the past few years. The growth that the business has experienced due to artificial intelligence (AI) turned Nvidia into one of the most valuable companies in the world today, with a market cap of ar…</p>
      <button class="btn btn-primary" type="button" data-bs-toggle="collapse" data-bs-target="#collapse1" aria-expanded="false" aria-controls="collapse1">
        Read More
      </button>
      <div class="collapse mt-2" id="collapse1">
        <div class="card card-body">
          <p>This story appeared on <a href="https://biztoc.com/x/d85ace1289f8ab9c" target="_blank">original source</a>.</p>
          <a href="https://biztoc.com/x/d85ace1289f8ab9c" target="_blank">Visit Original Article</a>
        </div>
      </div>
      <p class="card-text pub-date" data-pub-date="2025-03-06T11:52:12Z">
        <small class="text-muted">Published at: 2025-03-06 11:52</small>
      </p>
    </div>
  </div>

  <div class="card mb-3">
    <img src="https://d.newsweek.com/en/full/2601485/manus-china-ai.jpg" class="card-img-top" alt="What is Manus? China's World-First Fully Autonomous AI Agent Explained">
    <div class="card-body">
      <h5 class="card-title">What is Manus? China's World-First Fully Autonomous AI Agent Explained</h5>
      <p class="card-text">The new AI tool is designed to tackle "real-world" tasks, rather than simply generating copy.</p>
      <button class="btn btn-primary" type="button" data-bs-toggle="collapse" data-bs-target="#collapse2" aria-expanded="false" aria-controls="collapse2">
        Read More
      </button>
      <div class="collapse mt-2" id="collapse2">
        <div class="card card-body">
          <p>Full article not available. Please click 'Visit Original Article'.</p>
          <a href="https://www.newsweek.com/manus-new-china-ai-agent-explained-2040445" target="_blank">Visit Original Article</a>
        </div>
      </div>
      <p class="card-text pub-date" data-pub-date="2025-03-06T11:51:28Z">
        <small class="text-muted">Published at: 2025-03-06 11:51</small>
      </p>
    </div>
  </div>

</div>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script>
document.addEventListener('DOMContentLoaded', function() {
  const lastSeen = localStorage.getItem('lastSeen');
  const cards = document.querySelectorAll('.card.mb-3');
  let dividerInserted = false;
  if (lastSeen) {
    cards.forEach(card => {
      const pubDateElem = card.querySelector('.pub-date');
      if (pubDateElem) {
        const pubDate = new Date(pubDateElem.getAttribute('data-pub-date'));
        if (pubDate < new Date(lastSeen) && !dividerInserted) {
          const divider = document.createElement('div');
          divider.className = 'divider';
          divider.innerText = 'Previously Seen Articles';
          card.parentNode.insertBefore(divider, card);
          dividerInserted = true;
        }
      }
    });
  }
  if (cards.length > 0) {
    const firstPubDate = cards[0].querySelector('.pub-date').getAttribute('data-pub-date');
    localStorage.setItem('lastSeen', firstPubDate);
  }
});
</script>
</body>
</html>
